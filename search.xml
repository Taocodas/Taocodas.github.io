<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>爬虫学习之爬取糗图百科</title>
    <url>/2021/03/08/blog/</url>
    <content><![CDATA[<h2 id="导入所需要的库"><a href="#导入所需要的库" class="headerlink" title="导入所需要的库"></a>导入所需要的库</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import requests</span><br><span class="line">import re</span><br><span class="line">import os</span><br></pre></td></tr></table></figure>
<h2 id="为图片创造存储路径并且进行UA伪装"><a href="#为图片创造存储路径并且进行UA伪装" class="headerlink" title="为图片创造存储路径并且进行UA伪装"></a>为图片创造存储路径并且进行UA伪装</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if __name__ &#x3D;&#x3D;&#39;__main__&#39;:</span><br><span class="line">    if not os.path.exists(&#39;.&#x2F;qiutuLibs&#39;):</span><br><span class="line">        os.mkdir(&#39;.&#x2F;qiutuLibs&#39;)</span><br><span class="line">    url &#x3D; &#39;https:&#x2F;&#x2F;www.qiushibaike.com&#x2F;imgrank&#x2F;&#39;</span><br><span class="line">    headers &#x3D; &#123;</span><br><span class="line">        &#39;User-Agent&#39;: &#39;Mozilla&#x2F;5.0 (Windows NT 6.1; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;87.0.4280.141 Safari&#x2F;537.36&#39;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h2 id="先使用通用爬虫爬取页面的全部内容"><a href="#先使用通用爬虫爬取页面的全部内容" class="headerlink" title="先使用通用爬虫爬取页面的全部内容"></a>先使用通用爬虫爬取页面的全部内容</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">page_text &#x3D; requests.get(url&#x3D;url,headers&#x3D;headers).text</span><br></pre></td></tr></table></figure>
<h2 id="使用聚焦爬虫对页面中的所有糗图进行提取"><a href="#使用聚焦爬虫对页面中的所有糗图进行提取" class="headerlink" title="使用聚焦爬虫对页面中的所有糗图进行提取"></a>使用聚焦爬虫对页面中的所有糗图进行提取</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ex &#x3D; &#39;&lt;div class&#x3D;&quot;thumb&quot;&gt;.*?&lt;img src&#x3D;&quot;(.*?)&quot; alt.*?&lt;&#x2F;div&gt;&#39;</span><br><span class="line">img_src_list &#x3D; re.findall(ex,page_text,re.S)</span><br><span class="line">#print(img_src_list)</span><br><span class="line">for src in img_src_list:</span><br><span class="line">    src &#x3D; &#39;https:&#39;+src</span><br><span class="line">    img_data &#x3D; requests.get(url&#x3D;src,headers&#x3D;headers).content</span><br><span class="line">    image_name &#x3D; src.split(&#39;&#x2F;&#39;)[-1]</span><br><span class="line">    image_Path &#x3D; &#39;.&#x2F;qiutuLibs&#x2F;&#39; + image_name</span><br><span class="line">    with open(image_Path,&#39;wb&#39;) as fp:#文件名不要加引号</span><br><span class="line">        fp.write(img_data)</span><br><span class="line">        print(image_name,&#39;下载成功&#39;)</span><br></pre></td></tr></table></figure>
<h2 id="至此，图片的爬取实现成功！！！"><a href="#至此，图片的爬取实现成功！！！" class="headerlink" title="至此，图片的爬取实现成功！！！"></a>至此，图片的爬取实现成功！！！</h2>]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title>爬虫学习之爬取梨视频</title>
    <url>/2021/03/08/blog3/</url>
    <content><![CDATA[<h2 id="导入库"><a href="#导入库" class="headerlink" title="导入库"></a>导入库</h2><h4 id="xpath-selenium"><a href="#xpath-selenium" class="headerlink" title="xpath + selenium"></a>xpath + selenium</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import requests</span><br><span class="line">from lxml import etree</span><br><span class="line">from selenium import webdriver</span><br></pre></td></tr></table></figure>
<h2 id="指定url"><a href="#指定url" class="headerlink" title="指定url"></a>指定url</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">url_list &#x3D; []</span><br><span class="line">video_name &#x3D; []</span><br><span class="line">if __name__ &#x3D;&#x3D; &#39;__main__&#39;:</span><br><span class="line">    url &#x3D; &#39;https:&#x2F;&#x2F;www.pearvideo.com&#x2F;category_31&#39;</span><br><span class="line">    headers &#x3D; &#123;</span><br><span class="line">    &#39;User-Agent&#39;: &#39;Mozilla&#x2F;5.0 (Windows NT 6.1; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;87.0.4280.141 Safari&#x2F;537.36&#39;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h2 id="获取页面源代码"><a href="#获取页面源代码" class="headerlink" title="获取页面源代码"></a>获取页面源代码</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">page_text &#x3D; requests.get(url&#x3D;url,headers&#x3D;headers).text</span><br></pre></td></tr></table></figure>
<h2 id="解析出视频详情页URL"><a href="#解析出视频详情页URL" class="headerlink" title="解析出视频详情页URL"></a>解析出视频详情页URL</h2><h4 id="首先解析出各个视频对应的数字地址"><a href="#首先解析出各个视频对应的数字地址" class="headerlink" title="首先解析出各个视频对应的数字地址"></a>首先解析出各个视频对应的数字地址</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tree &#x3D; etree.HTML(page_text)</span><br><span class="line">li_list &#x3D; tree.xpath(&#39;&#x2F;&#x2F;ul[@id&#x3D;&quot;categoryList&quot;]&#x2F;li&#39;)</span><br></pre></td></tr></table></figure>
<h4 id="拼接出详情页地址并获取视频的二进制数据-使用-content方法"><a href="#拼接出详情页地址并获取视频的二进制数据-使用-content方法" class="headerlink" title="拼接出详情页地址并获取视频的二进制数据(使用.content方法)"></a>拼接出详情页地址并获取视频的二进制数据(使用.content方法)</h4><h6 id="注意这里不能直接使用xpath解析视频地址，因为该地址是经过JS渲染，只有打开相应的界面隐藏的这块element才会被加载出来，所以我使用selenium模拟打开对应的界面然后再进行数据解析。"><a href="#注意这里不能直接使用xpath解析视频地址，因为该地址是经过JS渲染，只有打开相应的界面隐藏的这块element才会被加载出来，所以我使用selenium模拟打开对应的界面然后再进行数据解析。" class="headerlink" title="注意这里不能直接使用xpath解析视频地址，因为该地址是经过JS渲染，只有打开相应的界面隐藏的这块element才会被加载出来，所以我使用selenium模拟打开对应的界面然后再进行数据解析。"></a>注意这里不能直接使用xpath解析视频地址，因为该地址是经过JS渲染，只有打开相应的界面隐藏的这块element才会被加载出来，所以我使用selenium模拟打开对应的界面然后再进行数据解析。</h6><h6 id="要以二进制的形式写入数据"><a href="#要以二进制的形式写入数据" class="headerlink" title="要以二进制的形式写入数据"></a>要以二进制的形式写入数据</h6><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">browser &#x3D; webdriver.Chrome(executable_path&#x3D;&#39;.&#x2F;chromedriver&#39;)</span><br><span class="line">for li in li_list:</span><br><span class="line">    detail_url &#x3D; &#39;https:&#x2F;&#x2F;www.pearvideo.com&#x2F;&#39; + li.xpath(&#39;.&#x2F;&#x2F;div&#x2F;a&#x2F;@href&#39;)[0]</span><br><span class="line">    name &#x3D; li.xpath(&#39;.&#x2F;div&#x2F;a&#x2F;div[2]&#x2F;text()&#39;)[0] + &#39;.mp4&#39;</span><br><span class="line">    browser.get(detail_url)</span><br><span class="line">    new_page_text &#x3D; browser.page_source</span><br><span class="line">    new_tree &#x3D; etree.HTML(new_page_text)</span><br><span class="line">    video_list &#x3D; new_tree.xpath(&#39;&#x2F;&#x2F;div&#x2F;video&#x2F;@src&#39;)[0]</span><br><span class="line">    video &#x3D; requests.get(url&#x3D;video_list,headers&#x3D;headers).content</span><br><span class="line">    with open(name,&#39;wb&#39;) as fp:</span><br><span class="line">        fp.write(video)</span><br><span class="line">        print(name,&#39;下载成功！&#39;)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title>概率论</title>
    <url>/2021/03/08/blog4/</url>
    <content><![CDATA[<h6 id="测试能否在md中预览pdf"><a href="#测试能否在md中预览pdf" class="headerlink" title="测试能否在md中预览pdf"></a>测试能否在md中预览pdf</h6><div class="pdfobject-container" data-target="https://taocodas.github.io/book/概率论.pdf" data-height="500px"></div>]]></content>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title>社会分层背后的思考</title>
    <url>/2021/03/10/blog5/</url>
    <content><![CDATA[<p>近年来，人们愈发明显的看到在中国的社会分层现象。这也表明该种状况已经进入到一个较为严重的阶段，从表象上呈现为人们普遍的焦虑感、各种伪矛盾的凸显、圈子的离散化。</p>
<p>但从某种程度上讲，这恰恰说明中国改革开放的红利已经得到较为充分的释放，各种资源的集中度在上升以此发挥规模化和范围经济的优势。</p>
<p>以股票市场为例，按照自由流通市值的口径，中国前20%的上市公司市值从2017年占A股的40%到现在已经超过60%，就这还要低于美国市场的集中度，未来恐怕还会继续上升。</p>
<p>! <a href="https://ss0.bdstatic.com/70cFuHSh_Q1YnxGkpoWK1HF6hhy/it/u=2104712183,3067422213&fm=26&gp=0.jpg">图1</a></p>
<p>不过在本文看来，就社会分层本身含义而言，它是一个非常正常不过的现象。我通常将其类比于经济学中的自然失业率。</p>
<p>失业并不总是被迫的，有些人可能为了寻求更好的工作机会而处在空窗期，而有些人由于自身的专业技能与希望工作的企业不匹配而进行培训因而暂时性休业。</p>
<p>这些情况即使是在经济运行状态良好的状态下，哪怕只要愿意工作就能就业的情形下依然存在。所以自然失业率不可能为0 。</p>
<p>社会分层亦是如此，马克思在劳动价值论中明确的区分了人的简单劳动和复杂劳动，而社会又藉由劳动分工了人类。</p>
<p>! <a href="https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=1206225278,640705876&fm=26&gp=0.jpg">图二</a></p>
<p>尽管劳动没有高低之分，但对于尚处在工业性社会的我们，劳动的复杂度和稀缺性却被利润率高低决定了价值的大小。</p>
<p>而在资本的导向下我们还不得不被迫认同这样一种观点，谁能够创造的利润大，谁的资本认可度就高，而资本的认可往往是财富的源泉。</p>
<p>最后我们不得不用资本的认可度替代了劳动总价值作为人生的一部分信条。使得由这种社会形态下的劳动价值异化产生的社会分层却具有一种必然的趋势。</p>
<p>但社会分层一旦超出了它的自然尺度就会面临一系列社会问题，从而影响社会的和谐秩序。</p>
<p>如在当今的许多社交新闻下不乏看到这样的评论：“为什么科学家和研究人员赚的钱还不如一些戏子呢？”从中透露而出的不满管中窥豹，可见一斑。</p>
<p>其实任何一种看似不正常的现象或行为往往是在一种扭曲状态下而自然产生的结果。也许明星们的社会劳动价值比不上学者和科研人员，但她（他）们的商业价值和自身在信息时代能产生的巨大流量价值为资本所看重。</p>
<p>不论这些是否最终被企业和广告公司能够变现，这是资本市场给予的能够产生利润的明星们的价值衡量。</p>
<p>! <a href="https://ss1.bdstatic.com/70cFuXSh_Q1YnxGkpoWK1HF6hhy/it/u=3720088831,2521836392&fm=26&gp=0.jpg">图三</a></p>
<p>人们之所以会对诸如此类的现象满怀不满和愤懑，并不是简单的一句不患寡而患不均所概括的。</p>
<p>而是因为人们在自身文化背景以及社会制度下对自己或他人的实际付出和回报期望出现明显差异所产生的自我判断和反馈，用比较社会学的语言来说就是相对剥夺感。</p>
<p>这种剥夺感降低了人们对生活甚至是社会的满意度，因此这也是我们之所以竭力维护公平和正义行为的一个支点。</p>
<p>! <a href="https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=2179019197,1584924515&fm=26&gp=0.jpg">图四</a></p>
<p>现如今中国社会的分化现象加快，这也是中国处于新的社会转型时期的体现以及必须要面临的挑战。</p>
<p>如果不能在根源上杜绝这一现象的出现，能否继续保持经济增长奇迹，健全社会保障以及再分配乃至第三次分配体系，将是我们面临的主要难关。</p>
<p>而对于处在转型期的每个人而言，需要思考当湖泊演化为沼泽之时，那时我们该如何存在?</p>
]]></content>
      <categories>
        <category>思考</category>
      </categories>
      <tags>
        <tag>社会学</tag>
      </tags>
  </entry>
  <entry>
    <title>爬虫学习之爬取豆瓣电影</title>
    <url>/2021/03/08/blog2/</url>
    <content><![CDATA[<h2 id="导入第三方库"><a href="#导入第三方库" class="headerlink" title="导入第三方库"></a>导入第三方库</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import requests</span><br><span class="line">import json</span><br></pre></td></tr></table></figure>
<h2 id="指定url"><a href="#指定url" class="headerlink" title="指定url"></a>指定url</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if __name__ &#x3D;&#x3D; &quot;__main__&quot;:</span><br><span class="line">    get_url &#x3D;&#39;https:&#x2F;&#x2F;movie.douban.com&#x2F;j&#x2F;chart&#x2F;top_list&#39;</span><br></pre></td></tr></table></figure>
<h2 id="UA伪装"><a href="#UA伪装" class="headerlink" title="UA伪装"></a>UA伪装</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">headers &#x3D; &#123;</span><br><span class="line">    &#39;User-Agent&#39;:&#39;Mozilla&#x2F;5.0 (Windows NT 6.1; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;87.0.4280.141 Safari&#x2F;537.36&#39;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="URL需携带的参数处理"><a href="#URL需携带的参数处理" class="headerlink" title="URL需携带的参数处理"></a>URL需携带的参数处理</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">params &#x3D; &#123;</span><br><span class="line">    &#39;type&#39;: &#39;11&#39;,</span><br><span class="line">    &#39;interval_id&#39;: &#39;100:90&#39;,</span><br><span class="line">    &#39;action&#39;:&#39;&#39;,</span><br><span class="line">    &#39;start&#39;: &#39;0&#39;,</span><br><span class="line">    &#39;limit&#39;: &#39;100&#39;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="获取响应数据"><a href="#获取响应数据" class="headerlink" title="获取响应数据"></a>获取响应数据</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">response &#x3D; requests.get(url&#x3D;get_url,params&#x3D;params,headers&#x3D;headers)</span><br><span class="line">list_data &#x3D; response.json()</span><br></pre></td></tr></table></figure>
<h2 id="持久化存储"><a href="#持久化存储" class="headerlink" title="持久化存储"></a>持久化存储</h2><h3 id="注意以下的存储路径采取的是相对路径，所执行的代码文件和爬取的数据都放在了同一个项目文件下面，对于数据的处理使用了pandas将数据转换为了Excel存储的表格文件。"><a href="#注意以下的存储路径采取的是相对路径，所执行的代码文件和爬取的数据都放在了同一个项目文件下面，对于数据的处理使用了pandas将数据转换为了Excel存储的表格文件。" class="headerlink" title="注意以下的存储路径采取的是相对路径，所执行的代码文件和爬取的数据都放在了同一个项目文件下面，对于数据的处理使用了pandas将数据转换为了Excel存储的表格文件。"></a>注意以下的存储路径采取的是相对路径，所执行的代码文件和爬取的数据都放在了同一个项目文件下面，对于数据的处理使用了pandas将数据转换为了Excel存储的表格文件。</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">    columns &#x3D; []</span><br><span class="line">    fp &#x3D; open(&#39;.&#x2F;douban.json&#39;,&#39;w&#39;,encoding&#x3D;&#39;utf-8&#39;)</span><br><span class="line">    json.dump(list_data, fp&#x3D;fp, ensure_ascii&#x3D;False)</span><br><span class="line">    dict_list &#x3D; [&#39;title&#39;, &#39;regions&#39;, &#39;actors&#39;, &#39;score&#39;]</span><br><span class="line">    for i in range(0, 10):</span><br><span class="line">        for dic in dict_list:</span><br><span class="line">            if isinstance(list_data[i][dic], list):</span><br><span class="line">                for s in range(len(list_data[i][dic])):</span><br><span class="line">                    print(list_data[i][dic][s])</span><br><span class="line">            else:</span><br><span class="line">                print(list_data[i][dic])</span><br><span class="line">    fp.close()</span><br><span class="line">    with open(&#39;.&#x2F;douban.json&#39;, &#39;r&#39;, encoding&#x3D;&#39;utf-8&#39;) as f:</span><br><span class="line">        data_dict &#x3D; json.load(f)</span><br><span class="line">        for key in data_dict[0]:  # 拿到第一个字典，取字典中key</span><br><span class="line">            columns.append(key)</span><br><span class="line">    df &#x3D; pd.read_json(&#39;.&#x2F;douban.json&#39;, orient&#x3D;&#39;records&#39;, encoding&#x3D;&#39;utf-8&#39;)  # 读取json数据</span><br><span class="line">    df.to_excel(&#39;.&#x2F;pandas处理json.xlsx&#39;, index&#x3D;False, columns&#x3D;columns)  # 保存</span><br><span class="line">print(&#39;over!&#39;)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
</search>
