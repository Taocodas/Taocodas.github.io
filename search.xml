<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>爬虫学习之爬取糗图百科</title>
    <url>/2021/03/08/blog/</url>
    <content><![CDATA[<h2 id="导入所需要的库"><a href="#导入所需要的库" class="headerlink" title="导入所需要的库"></a>导入所需要的库</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import requests</span><br><span class="line">import re</span><br><span class="line">import os</span><br></pre></td></tr></table></figure>
<h2 id="为图片创造存储路径并且进行UA伪装"><a href="#为图片创造存储路径并且进行UA伪装" class="headerlink" title="为图片创造存储路径并且进行UA伪装"></a>为图片创造存储路径并且进行UA伪装</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if __name__ &#x3D;&#x3D;&#39;__main__&#39;:</span><br><span class="line">    if not os.path.exists(&#39;.&#x2F;qiutuLibs&#39;):</span><br><span class="line">        os.mkdir(&#39;.&#x2F;qiutuLibs&#39;)</span><br><span class="line">    url &#x3D; &#39;https:&#x2F;&#x2F;www.qiushibaike.com&#x2F;imgrank&#x2F;&#39;</span><br><span class="line">    headers &#x3D; &#123;</span><br><span class="line">        &#39;User-Agent&#39;: &#39;Mozilla&#x2F;5.0 (Windows NT 6.1; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;87.0.4280.141 Safari&#x2F;537.36&#39;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h2 id="先使用通用爬虫爬取页面的全部内容"><a href="#先使用通用爬虫爬取页面的全部内容" class="headerlink" title="先使用通用爬虫爬取页面的全部内容"></a>先使用通用爬虫爬取页面的全部内容</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">page_text &#x3D; requests.get(url&#x3D;url,headers&#x3D;headers).text</span><br></pre></td></tr></table></figure>
<h2 id="使用聚焦爬虫对页面中的所有糗图进行提取"><a href="#使用聚焦爬虫对页面中的所有糗图进行提取" class="headerlink" title="使用聚焦爬虫对页面中的所有糗图进行提取"></a>使用聚焦爬虫对页面中的所有糗图进行提取</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ex &#x3D; &#39;&lt;div class&#x3D;&quot;thumb&quot;&gt;.*?&lt;img src&#x3D;&quot;(.*?)&quot; alt.*?&lt;&#x2F;div&gt;&#39;</span><br><span class="line">img_src_list &#x3D; re.findall(ex,page_text,re.S)</span><br><span class="line">#print(img_src_list)</span><br><span class="line">for src in img_src_list:</span><br><span class="line">    src &#x3D; &#39;https:&#39;+src</span><br><span class="line">    img_data &#x3D; requests.get(url&#x3D;src,headers&#x3D;headers).content</span><br><span class="line">    image_name &#x3D; src.split(&#39;&#x2F;&#39;)[-1]</span><br><span class="line">    image_Path &#x3D; &#39;.&#x2F;qiutuLibs&#x2F;&#39; + image_name</span><br><span class="line">    with open(image_Path,&#39;wb&#39;) as fp:#文件名不要加引号</span><br><span class="line">        fp.write(img_data)</span><br><span class="line">        print(image_name,&#39;下载成功&#39;)</span><br></pre></td></tr></table></figure>
<h2 id="至此，图片的爬取实现成功！！！"><a href="#至此，图片的爬取实现成功！！！" class="headerlink" title="至此，图片的爬取实现成功！！！"></a>至此，图片的爬取实现成功！！！</h2>]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title>爬虫学习之爬取梨视频</title>
    <url>/2021/03/08/blog3/</url>
    <content><![CDATA[<h2 id="导入库"><a href="#导入库" class="headerlink" title="导入库"></a>导入库</h2><h4 id="xpath-selenium"><a href="#xpath-selenium" class="headerlink" title="xpath + selenium"></a>xpath + selenium</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import requests</span><br><span class="line">from lxml import etree</span><br><span class="line">from selenium import webdriver</span><br></pre></td></tr></table></figure>
<h2 id="指定url"><a href="#指定url" class="headerlink" title="指定url"></a>指定url</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">url_list &#x3D; []</span><br><span class="line">video_name &#x3D; []</span><br><span class="line">if __name__ &#x3D;&#x3D; &#39;__main__&#39;:</span><br><span class="line">    url &#x3D; &#39;https:&#x2F;&#x2F;www.pearvideo.com&#x2F;category_31&#39;</span><br><span class="line">    headers &#x3D; &#123;</span><br><span class="line">    &#39;User-Agent&#39;: &#39;Mozilla&#x2F;5.0 (Windows NT 6.1; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;87.0.4280.141 Safari&#x2F;537.36&#39;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h2 id="获取页面源代码"><a href="#获取页面源代码" class="headerlink" title="获取页面源代码"></a>获取页面源代码</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">page_text &#x3D; requests.get(url&#x3D;url,headers&#x3D;headers).text</span><br></pre></td></tr></table></figure>
<h2 id="解析出视频详情页URL"><a href="#解析出视频详情页URL" class="headerlink" title="解析出视频详情页URL"></a>解析出视频详情页URL</h2><h4 id="首先解析出各个视频对应的数字地址"><a href="#首先解析出各个视频对应的数字地址" class="headerlink" title="首先解析出各个视频对应的数字地址"></a>首先解析出各个视频对应的数字地址</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tree &#x3D; etree.HTML(page_text)</span><br><span class="line">li_list &#x3D; tree.xpath(&#39;&#x2F;&#x2F;ul[@id&#x3D;&quot;categoryList&quot;]&#x2F;li&#39;)</span><br></pre></td></tr></table></figure>
<h4 id="拼接出详情页地址并获取视频的二进制数据-使用-content方法"><a href="#拼接出详情页地址并获取视频的二进制数据-使用-content方法" class="headerlink" title="拼接出详情页地址并获取视频的二进制数据(使用.content方法)"></a>拼接出详情页地址并获取视频的二进制数据(使用.content方法)</h4><h6 id="注意这里不能直接使用xpath解析视频地址，因为该地址是经过JS渲染，只有打开相应的界面隐藏的这块element才会被加载出来，所以我使用selenium模拟打开对应的界面然后再进行数据解析。"><a href="#注意这里不能直接使用xpath解析视频地址，因为该地址是经过JS渲染，只有打开相应的界面隐藏的这块element才会被加载出来，所以我使用selenium模拟打开对应的界面然后再进行数据解析。" class="headerlink" title="注意这里不能直接使用xpath解析视频地址，因为该地址是经过JS渲染，只有打开相应的界面隐藏的这块element才会被加载出来，所以我使用selenium模拟打开对应的界面然后再进行数据解析。"></a>注意这里不能直接使用xpath解析视频地址，因为该地址是经过JS渲染，只有打开相应的界面隐藏的这块element才会被加载出来，所以我使用selenium模拟打开对应的界面然后再进行数据解析。</h6><h6 id="要以二进制的形式写入数据"><a href="#要以二进制的形式写入数据" class="headerlink" title="要以二进制的形式写入数据"></a>要以二进制的形式写入数据</h6><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">browser &#x3D; webdriver.Chrome(executable_path&#x3D;&#39;.&#x2F;chromedriver&#39;)</span><br><span class="line">for li in li_list:</span><br><span class="line">    detail_url &#x3D; &#39;https:&#x2F;&#x2F;www.pearvideo.com&#x2F;&#39; + li.xpath(&#39;.&#x2F;&#x2F;div&#x2F;a&#x2F;@href&#39;)[0]</span><br><span class="line">    name &#x3D; li.xpath(&#39;.&#x2F;div&#x2F;a&#x2F;div[2]&#x2F;text()&#39;)[0] + &#39;.mp4&#39;</span><br><span class="line">    browser.get(detail_url)</span><br><span class="line">    new_page_text &#x3D; browser.page_source</span><br><span class="line">    new_tree &#x3D; etree.HTML(new_page_text)</span><br><span class="line">    video_list &#x3D; new_tree.xpath(&#39;&#x2F;&#x2F;div&#x2F;video&#x2F;@src&#39;)[0]</span><br><span class="line">    video &#x3D; requests.get(url&#x3D;video_list,headers&#x3D;headers).content</span><br><span class="line">    with open(name,&#39;wb&#39;) as fp:</span><br><span class="line">        fp.write(video)</span><br><span class="line">        print(name,&#39;下载成功！&#39;)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title>概率论</title>
    <url>/2021/03/08/blog4/</url>
    <content><![CDATA[<h6 id="测试能否在md中预览pdf"><a href="#测试能否在md中预览pdf" class="headerlink" title="测试能否在md中预览pdf"></a>测试能否在md中预览pdf</h6><div class="pdfobject-container" data-target="https://taocodas.github.io/book/概率论.pdf" data-height="500px"></div>]]></content>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title>爬虫学习之爬取豆瓣电影</title>
    <url>/2021/03/08/blog2/</url>
    <content><![CDATA[<h2 id="导入第三方库"><a href="#导入第三方库" class="headerlink" title="导入第三方库"></a>导入第三方库</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import requests</span><br><span class="line">import json</span><br></pre></td></tr></table></figure>
<h2 id="指定url"><a href="#指定url" class="headerlink" title="指定url"></a>指定url</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if __name__ &#x3D;&#x3D; &quot;__main__&quot;:</span><br><span class="line">    get_url &#x3D;&#39;https:&#x2F;&#x2F;movie.douban.com&#x2F;j&#x2F;chart&#x2F;top_list&#39;</span><br></pre></td></tr></table></figure>
<h2 id="UA伪装"><a href="#UA伪装" class="headerlink" title="UA伪装"></a>UA伪装</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">headers &#x3D; &#123;</span><br><span class="line">    &#39;User-Agent&#39;:&#39;Mozilla&#x2F;5.0 (Windows NT 6.1; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;87.0.4280.141 Safari&#x2F;537.36&#39;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="URL需携带的参数处理"><a href="#URL需携带的参数处理" class="headerlink" title="URL需携带的参数处理"></a>URL需携带的参数处理</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">params &#x3D; &#123;</span><br><span class="line">    &#39;type&#39;: &#39;11&#39;,</span><br><span class="line">    &#39;interval_id&#39;: &#39;100:90&#39;,</span><br><span class="line">    &#39;action&#39;:&#39;&#39;,</span><br><span class="line">    &#39;start&#39;: &#39;0&#39;,</span><br><span class="line">    &#39;limit&#39;: &#39;100&#39;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="获取响应数据"><a href="#获取响应数据" class="headerlink" title="获取响应数据"></a>获取响应数据</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">response &#x3D; requests.get(url&#x3D;get_url,params&#x3D;params,headers&#x3D;headers)</span><br><span class="line">list_data &#x3D; response.json()</span><br></pre></td></tr></table></figure>
<h2 id="持久化存储"><a href="#持久化存储" class="headerlink" title="持久化存储"></a>持久化存储</h2><h3 id="注意以下的存储路径采取的是相对路径，所执行的代码文件和爬取的数据都放在了同一个项目文件下面，对于数据的处理使用了pandas将数据转换为了Excel存储的表格文件。"><a href="#注意以下的存储路径采取的是相对路径，所执行的代码文件和爬取的数据都放在了同一个项目文件下面，对于数据的处理使用了pandas将数据转换为了Excel存储的表格文件。" class="headerlink" title="注意以下的存储路径采取的是相对路径，所执行的代码文件和爬取的数据都放在了同一个项目文件下面，对于数据的处理使用了pandas将数据转换为了Excel存储的表格文件。"></a>注意以下的存储路径采取的是相对路径，所执行的代码文件和爬取的数据都放在了同一个项目文件下面，对于数据的处理使用了pandas将数据转换为了Excel存储的表格文件。</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">    columns &#x3D; []</span><br><span class="line">    fp &#x3D; open(&#39;.&#x2F;douban.json&#39;,&#39;w&#39;,encoding&#x3D;&#39;utf-8&#39;)</span><br><span class="line">    json.dump(list_data, fp&#x3D;fp, ensure_ascii&#x3D;False)</span><br><span class="line">    dict_list &#x3D; [&#39;title&#39;, &#39;regions&#39;, &#39;actors&#39;, &#39;score&#39;]</span><br><span class="line">    for i in range(0, 10):</span><br><span class="line">        for dic in dict_list:</span><br><span class="line">            if isinstance(list_data[i][dic], list):</span><br><span class="line">                for s in range(len(list_data[i][dic])):</span><br><span class="line">                    print(list_data[i][dic][s])</span><br><span class="line">            else:</span><br><span class="line">                print(list_data[i][dic])</span><br><span class="line">    fp.close()</span><br><span class="line">    with open(&#39;.&#x2F;douban.json&#39;, &#39;r&#39;, encoding&#x3D;&#39;utf-8&#39;) as f:</span><br><span class="line">        data_dict &#x3D; json.load(f)</span><br><span class="line">        for key in data_dict[0]:  # 拿到第一个字典，取字典中key</span><br><span class="line">            columns.append(key)</span><br><span class="line">    df &#x3D; pd.read_json(&#39;.&#x2F;douban.json&#39;, orient&#x3D;&#39;records&#39;, encoding&#x3D;&#39;utf-8&#39;)  # 读取json数据</span><br><span class="line">    df.to_excel(&#39;.&#x2F;pandas处理json.xlsx&#39;, index&#x3D;False, columns&#x3D;columns)  # 保存</span><br><span class="line">print(&#39;over!&#39;)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
</search>
