<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>爬虫学习之爬取糗图百科</title>
    <url>/2021/03/08/blog/</url>
    <content><![CDATA[<h2 id="导入所需要的库"><a href="#导入所需要的库" class="headerlink" title="导入所需要的库"></a>导入所需要的库</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import requests</span><br><span class="line">import re</span><br><span class="line">import os</span><br></pre></td></tr></table></figure>
<h2 id="为图片创造存储路径并且进行UA伪装"><a href="#为图片创造存储路径并且进行UA伪装" class="headerlink" title="为图片创造存储路径并且进行UA伪装"></a>为图片创造存储路径并且进行UA伪装</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if __name__ &#x3D;&#x3D;&#39;__main__&#39;:</span><br><span class="line">    if not os.path.exists(&#39;.&#x2F;qiutuLibs&#39;):</span><br><span class="line">        os.mkdir(&#39;.&#x2F;qiutuLibs&#39;)</span><br><span class="line">    url &#x3D; &#39;https:&#x2F;&#x2F;www.qiushibaike.com&#x2F;imgrank&#x2F;&#39;</span><br><span class="line">    headers &#x3D; &#123;</span><br><span class="line">        &#39;User-Agent&#39;: &#39;Mozilla&#x2F;5.0 (Windows NT 6.1; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;87.0.4280.141 Safari&#x2F;537.36&#39;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h2 id="先使用通用爬虫爬取页面的全部内容"><a href="#先使用通用爬虫爬取页面的全部内容" class="headerlink" title="先使用通用爬虫爬取页面的全部内容"></a>先使用通用爬虫爬取页面的全部内容</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">page_text &#x3D; requests.get(url&#x3D;url,headers&#x3D;headers).text</span><br></pre></td></tr></table></figure>
<h2 id="使用聚焦爬虫对页面中的所有糗图进行提取"><a href="#使用聚焦爬虫对页面中的所有糗图进行提取" class="headerlink" title="使用聚焦爬虫对页面中的所有糗图进行提取"></a>使用聚焦爬虫对页面中的所有糗图进行提取</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ex &#x3D; &#39;&lt;div class&#x3D;&quot;thumb&quot;&gt;.*?&lt;img src&#x3D;&quot;(.*?)&quot; alt.*?&lt;&#x2F;div&gt;&#39;</span><br><span class="line">img_src_list &#x3D; re.findall(ex,page_text,re.S)</span><br><span class="line">#print(img_src_list)</span><br><span class="line">for src in img_src_list:</span><br><span class="line">    src &#x3D; &#39;https:&#39;+src</span><br><span class="line">    img_data &#x3D; requests.get(url&#x3D;src,headers&#x3D;headers).content</span><br><span class="line">    image_name &#x3D; src.split(&#39;&#x2F;&#39;)[-1]</span><br><span class="line">    image_Path &#x3D; &#39;.&#x2F;qiutuLibs&#x2F;&#39; + image_name</span><br><span class="line">    with open(image_Path,&#39;wb&#39;) as fp:#文件名不要加引号</span><br><span class="line">        fp.write(img_data)</span><br><span class="line">        print(image_name,&#39;下载成功&#39;)</span><br></pre></td></tr></table></figure>
<h2 id="至此，图片的爬取实现成功！！！"><a href="#至此，图片的爬取实现成功！！！" class="headerlink" title="至此，图片的爬取实现成功！！！"></a>至此，图片的爬取实现成功！！！</h2>]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2021/03/07/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>爬虫学习之爬取豆瓣电影</title>
    <url>/2021/03/08/blog2/</url>
    <content><![CDATA[<h2 id="导入第三方库"><a href="#导入第三方库" class="headerlink" title="导入第三方库"></a>导入第三方库</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line">import requests</span><br><span class="line">import json</span><br></pre></td></tr></table></figure>
<h2 id="指定url"><a href="#指定url" class="headerlink" title="指定url"></a>指定url</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if __name__ &#x3D;&#x3D; &quot;__main__&quot;:</span><br><span class="line">    get_url &#x3D;&#39;https:&#x2F;&#x2F;movie.douban.com&#x2F;j&#x2F;chart&#x2F;top_list&#39;</span><br></pre></td></tr></table></figure>
<h2 id="UA伪装"><a href="#UA伪装" class="headerlink" title="UA伪装"></a>UA伪装</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">headers &#x3D; &#123;</span><br><span class="line">    &#39;User-Agent&#39;:&#39;Mozilla&#x2F;5.0 (Windows NT 6.1; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;87.0.4280.141 Safari&#x2F;537.36&#39;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="URL需携带的参数处理"><a href="#URL需携带的参数处理" class="headerlink" title="URL需携带的参数处理"></a>URL需携带的参数处理</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">params &#x3D; &#123;</span><br><span class="line">    &#39;type&#39;: &#39;11&#39;,</span><br><span class="line">    &#39;interval_id&#39;: &#39;100:90&#39;,</span><br><span class="line">    &#39;action&#39;:&#39;&#39;,</span><br><span class="line">    &#39;start&#39;: &#39;0&#39;,</span><br><span class="line">    &#39;limit&#39;: &#39;100&#39;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="获取响应数据"><a href="#获取响应数据" class="headerlink" title="获取响应数据"></a>获取响应数据</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">response &#x3D; requests.get(url&#x3D;get_url,params&#x3D;params,headers&#x3D;headers)</span><br><span class="line">list_data &#x3D; response.json()</span><br></pre></td></tr></table></figure>
<h2 id="持久化存储"><a href="#持久化存储" class="headerlink" title="持久化存储"></a>持久化存储</h2><h3 id="注意以下的存储路径采取的是相对路径，所执行的代码文件和爬取的数据都放在了同一个项目文件下面，对于数据的处理使用了pandas将数据转换为了Excel存储的表格文件。"><a href="#注意以下的存储路径采取的是相对路径，所执行的代码文件和爬取的数据都放在了同一个项目文件下面，对于数据的处理使用了pandas将数据转换为了Excel存储的表格文件。" class="headerlink" title="注意以下的存储路径采取的是相对路径，所执行的代码文件和爬取的数据都放在了同一个项目文件下面，对于数据的处理使用了pandas将数据转换为了Excel存储的表格文件。"></a>注意以下的存储路径采取的是相对路径，所执行的代码文件和爬取的数据都放在了同一个项目文件下面，对于数据的处理使用了pandas将数据转换为了Excel存储的表格文件。</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">    columns &#x3D; []</span><br><span class="line">    fp &#x3D; open(&#39;.&#x2F;douban.json&#39;,&#39;w&#39;,encoding&#x3D;&#39;utf-8&#39;)</span><br><span class="line">    json.dump(list_data, fp&#x3D;fp, ensure_ascii&#x3D;False)</span><br><span class="line">    dict_list &#x3D; [&#39;title&#39;, &#39;regions&#39;, &#39;actors&#39;, &#39;score&#39;]</span><br><span class="line">    for i in range(0, 10):</span><br><span class="line">        for dic in dict_list:</span><br><span class="line">            if isinstance(list_data[i][dic], list):</span><br><span class="line">                for s in range(len(list_data[i][dic])):</span><br><span class="line">                    print(list_data[i][dic][s])</span><br><span class="line">            else:</span><br><span class="line">                print(list_data[i][dic])</span><br><span class="line">    fp.close()</span><br><span class="line">    with open(&#39;.&#x2F;douban.json&#39;, &#39;r&#39;, encoding&#x3D;&#39;utf-8&#39;) as f:</span><br><span class="line">        data_dict &#x3D; json.load(f)</span><br><span class="line">        for key in data_dict[0]:  # 拿到第一个字典，取字典中key</span><br><span class="line">            columns.append(key)</span><br><span class="line">    df &#x3D; pd.read_json(&#39;.&#x2F;douban.json&#39;, orient&#x3D;&#39;records&#39;, encoding&#x3D;&#39;utf-8&#39;)  # 读取json数据</span><br><span class="line">    df.to_excel(&#39;.&#x2F;pandas处理json.xlsx&#39;, index&#x3D;False, columns&#x3D;columns)  # 保存</span><br><span class="line">print(&#39;over!&#39;)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
</search>
